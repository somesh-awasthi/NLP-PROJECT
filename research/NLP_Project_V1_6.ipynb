{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rf6WfhB2TOtV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain langchain-openai langchainhub\n",
        "!pip install ctransformers sentence-transformers langchain-chroma\n",
        "!pip install pandas nltk spacy PyPDF\n",
        "%pip install --upgrade --quiet  sentence-transformers langchain-chroma langchain langchain-openai > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYcX0xlDT-oF",
        "outputId": "2941df86-6a30-455b-cace-cba690dfeb7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connecting to database\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "path=\"/content/drive/MyDrive/Colab Notebooks/nlp/data/book\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aJ_0BrNULGh"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "# Load documents from PDF\n",
        "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8YwiR4oM2D3"
      },
      "outputs": [],
      "source": [
        "def partition_doc():\n",
        "    raw_pdf_elements = partition_pdf(\n",
        "        filename= DATA_PATH + \"/docmerged.pdf\",\n",
        "        extract_images_in_pdf=False,\n",
        "        infer_table_structure=True,\n",
        "        chunking_strategy=\"by_title\",\n",
        "        max_characters=6000,\n",
        "        new_after_n_chars=3800,\n",
        "        combine_text_under_n_chars=2000,\n",
        "    )\n",
        "\n",
        "    # Categorize by type\n",
        "    tables = []\n",
        "    texts = []\n",
        "\n",
        "    for element in raw_pdf_elements:\n",
        "        if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
        "            tables.append(str(element))\n",
        "        elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
        "            texts.append(str(element))\n",
        "\n",
        "    print(len(tables), \" \", len(texts))\n",
        "    # Prompt\n",
        "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text. \\\n",
        "    Give a concise summary of the table or text. Table or text chunk: {element} \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
        "\n",
        "    # Summary chain\n",
        "    model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
        "\n",
        "    table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\n",
        "\n",
        "    return table_summaries, texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLbSe5sFdNoQ"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    # Tokenization and POS tagging using SpaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Filtering out tokens based on POS tags and dependency parsing\n",
        "    filtered_tokens = []\n",
        "    for token in doc:\n",
        "        if token.pos_ not in [\"SPACE\", \"X\"]:\n",
        "            if token.dep_ not in [\"det\", \"punct\"]:\n",
        "                filtered_tokens.append(token.text.lower())\n",
        "\n",
        "    # Stopword removal\n",
        "    filtered_tokens = [token for token in filtered_tokens if token not in stopwords.words('english')]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatized_tokens = [token.lemma_ for token in nlp(\" \".join(filtered_tokens))]\n",
        "\n",
        "    return \" \".join(lemmatized_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VX4-4iqUrhn",
        "outputId": "53c8ec4c-4dbd-49d8-df10-1baae46661bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split 4762 documents into 38997 chunks.\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "for doc in documents:\n",
        "  doc.page_content = preprocess_text(doc.page_content)\n",
        "\n",
        "# Split the preprocessed documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        "    add_start_index=True,\n",
        ")\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEya05vCUvHX"
      },
      "outputs": [],
      "source": [
        "# Save preprocessed chunks to Chroma\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass('Enter your OpenAI API key:')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass('Enter your LANGCHAIN API key:')\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
        "# db = Chroma.from_documents(chunks, OpenAIEmbeddings(), persist_directory=\"./drive/MyDrive/Colab Notebooks/nlp/chroma_db-v(Harrison-mehta)\")\n",
        "db = Chroma(embedding_function=OpenAIEmbeddings(), persist_directory=\"./drive/MyDrive/Colab Notebooks/nlp/chroma_db-v(Harrison-mehta)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvQMSbNmfqDN",
        "outputId": "e9416f88-29ba-4eeb-8593-782c24983728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4920 entries, 0 to 4919\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Disease   4920 non-null   object\n",
            " 1   Symptoms  4920 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 77.0+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/nlp/data/disease symptom prediction/testset.csv')\n",
        "df.head(10)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXHDEry0sG4N",
        "outputId": "58545ada-c18c-49ba-d1f6-0c05fc2c7434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  Disease                                           Symptoms\n",
            "4287          Hepatitis E   joint_pain, vomiting, fatigue, high_fever, ye...\n",
            "4135            Arthritis   muscle_weakness, stiff_neck, swelling_joints,...\n",
            "3585              Typhoid   chills, vomiting, fatigue, high_fever, headac...\n",
            "68                   AIDS   muscle_wasting, high_fever, extra_marital_con...\n",
            "4904         Tuberculosis   chills, vomiting, fatigue, weight_loss, cough...\n",
            "1696  Peptic ulcer diseae   vomiting, indigestion, loss_of_appetite, abdo...\n",
            "4102                 GERD   stomach_pain, acidity, ulcers_on_tongue, vomi...\n",
            "1073         Tuberculosis   chills, fatigue, weight_loss, cough, high_fev...\n",
            "4094            Arthritis   muscle_weakness, stiff_neck, swelling_joints,...\n",
            "3930            Arthritis   muscle_weakness, stiff_neck, swelling_joints,...\n"
          ]
        }
      ],
      "source": [
        "df = df.sample(n=10)\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goj40ES2xAyo",
        "outputId": "88db0804-e71d-4295-e99a-0d750489b2c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"\\nUse the following pieces of information to answer the user's question.\\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nContext: {context}\\nQuestion: {question}\\n\\nOnly return the helpful answer below and nothing else.\\nHelpful answer:\\n\"))])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Use the following pieces of information to answer the user's question.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\n",
        "Only return the helpful answer below and nothing else.\n",
        "Helpful answer:\n",
        "\"\"\"\n",
        "prompt=ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVyOQzmUbZYf"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import LLMChain, StuffDocumentsChain\n",
        "from langchain_community.document_transformers import (\n",
        "    LongContextReorder,\n",
        ")\n",
        "# Start conversation loop\n",
        "context_text = \"\"\n",
        "while True:\n",
        "    query_text = input(\"Enter your query (type 'quit' to exit): \")\n",
        "\n",
        "    if query_text.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    # Search the DB.\n",
        "    results = db.similarity_search_with_relevance_scores(query_text, k=7)\n",
        "\n",
        "    # Reorder documents\n",
        "    reordering = LongContextReorder()\n",
        "    reorder_docs = reordering.transform_documents(results)\n",
        "\n",
        "    if len(reorder_docs) == 0 or reorder_docs[0][1] < 0.7:\n",
        "        print(f\"Unable to find matching results.\")\n",
        "        continue\n",
        "\n",
        "    new_context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in reorder_docs])\n",
        "    context_text += \"\\n\\n---\\n\\n\" + new_context_text\n",
        "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
        "    # print(prompt)\n",
        "\n",
        "    model = ChatOpenAI()\n",
        "    response_text = model.invoke(prompt)\n",
        "\n",
        "    # Load the model\n",
        "    sources = [doc.metadata.get(\"source\", None) for doc, _score in reorder_docs]\n",
        "    formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
        "    print(formatted_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obnW2edrkCVS",
        "outputId": "2d6e1d28-71b8-4055-be56-d8e153a3816e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['actual_disease', 'predicted_disease_sentence'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['actual_disease', 'predicted_disease_sentence'], template='\\ngiven you are 2 answer one is actual disease and another one is predicted disease sentence \\nyour task is to give ans in 0 or 1 \\nwhere 0 is both actual_disease and predicted_disease_sentence are different\\nwhere 1 is both actual_disease and predicted_disease_sentence are similar\\nactual ans : {actual_disease}\\npredicted ans : {predicted_disease_sentence}\\nOnly return the answer in 0 or 1\\n'))])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "PROMPT_TEMPLATE_COMPARE = \"\"\"\n",
        "given you are 2 answer one is actual disease and another one is predicted disease sentence\n",
        "your task is to give ans in 0 or 1\n",
        "where 0 is both actual_disease and predicted_disease_sentence are different\n",
        "where 1 is both actual_disease and predicted_disease_sentence are similar\n",
        "actual ans : {actual_disease}\n",
        "predicted ans : {predicted_disease_sentence}\n",
        "Only return the answer in 0 or 1\n",
        "\"\"\"\n",
        "prompt_compare=ChatPromptTemplate.from_template(PROMPT_TEMPLATE_COMPARE)\n",
        "prompt_compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_iSrBgWmVY2"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import LLMChain, StuffDocumentsChain\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.document_transformers import LongContextReorder\n",
        "\n",
        "# Start conversation loop\n",
        "def search(query_text):\n",
        "    # Search the DB.\n",
        "    context_text = \"\"\n",
        "    results = db.similarity_search_with_relevance_scores(query_text, k=7)\n",
        "\n",
        "    # Reorder documents\n",
        "    reordering = LongContextReorder()\n",
        "    reorder_docs = reordering.transform_documents(results)\n",
        "\n",
        "    if len(reorder_docs) == 0 or reorder_docs[0][1] < 0.7:\n",
        "        print(f\"Unable to find matching results.\")\n",
        "        return\n",
        "\n",
        "    new_context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in reorder_docs])\n",
        "    context_text += \"\\n\\n---\\n\\n\" + new_context_text\n",
        "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
        "    # print(prompt)\n",
        "\n",
        "    model = ChatOpenAI() | StrOutputParser()\n",
        "    response_text = model.invoke(prompt)\n",
        "\n",
        "    # Load the model\n",
        "    sources = [doc.metadata.get(\"source\", None) for doc, _score in reorder_docs]\n",
        "    return response_text\n",
        "\n",
        "def compare(actual_disease, predicted_disease_sentence):\n",
        "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE_COMPARE)\n",
        "    prompt_compare = prompt_template.format(actual_disease=actual_disease, predicted_disease_sentence=predicted_disease_sentence)\n",
        "    model = ChatOpenAI() | StrOutputParser()\n",
        "    response_text = model.invoke(prompt_compare)\n",
        "    print(response_text)\n",
        "    if '0' in response_text:\n",
        "        return 0\n",
        "    elif '1' in response_text:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAgeMlD1ow9p",
        "outputId": "9a58befe-2c5e-4610-8cc5-def592b3821f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "symptoms :  joint_pain, vomiting, fatigue, high_fever, yellowish_skin, dark_urine, nausea, loss_of_appetite, abdominal_pain, yellowing_of_eyes, acute_liver_failure, coma, stomach_bleeding \n",
            " actual_disease : Hepatitis E\n",
            "predicted_disease_sentence : The symptoms mentioned are suggestive of liver disease, possibly hepatitis or liver failure. It is important to consult a healthcare provider for proper evaluation and diagnosis.\n",
            "\n",
            "\n",
            "1\n",
            "\n",
            "symptoms :  muscle_weakness, stiff_neck, swelling_joints, movement_stiffness, painful_walking \n",
            " actual_disease : Arthritis\n",
            "predicted_disease_sentence : The information provided suggests that the individual may be experiencing symptoms related to inflammatory myopathies, arthritis, and stiff-person syndrome. It is recommended to consult with a healthcare professional for a proper diagnosis and treatment plan.\n",
            "\n",
            "\n",
            "1\n",
            "\n",
            "symptoms :  chills, vomiting, fatigue, high_fever, headache, nausea, constipation, abdominal_pain, diarrhoea, toxic_look_(typhos), belly_pain \n",
            " actual_disease : Typhoid\n",
            "predicted_disease_sentence : These symptoms are suggestive of typhoid fever.\n",
            "\n",
            "\n",
            "1\n",
            "\n",
            "symptoms :  muscle_wasting, high_fever, extra_marital_contacts \n",
            " actual_disease : AIDS\n",
            "predicted_disease_sentence : I don't know.\n",
            "\n",
            "\n",
            "0\n",
            "\n",
            "symptoms :  chills, vomiting, fatigue, weight_loss, cough, high_fever, breathlessness, sweating, loss_of_appetite, mild_fever, yellowing_of_eyes, swelled_lymph_nodes, malaise, phlegm, chest_pain, blood_in_sputum \n",
            " actual_disease : Tuberculosis\n",
            "predicted_disease_sentence : The symptoms described could be indicative of tuberculosis.\n",
            "\n",
            "\n",
            "1\n",
            "\n",
            "symptoms :  vomiting, indigestion, loss_of_appetite, abdominal_pain, internal_itching \n",
            " actual_disease : Peptic ulcer diseae\n",
            "predicted_disease_sentence : Nausea, vomiting, indigestion, loss of appetite, and abdominal pain can be caused by a variety of gastrointestinal issues, such as gastritis, peptic ulcers, intestinal obstruction, and inflammatory bowel diseases. It is important to consult a healthcare professional for proper diagnosis and treatment.\n",
            "\n",
            "\n",
            "1\n",
            "\n",
            "symptoms :  stomach_pain, acidity, ulcers_on_tongue, vomiting, cough, chest_pain \n",
            " actual_disease : GERD\n",
            "predicted_disease_sentence : I don't know.\n",
            "\n",
            "\n",
            "0\n",
            "\n",
            "symptoms :  chills, fatigue, weight_loss, cough, high_fever, breathlessness, sweating, loss_of_appetite, mild_fever, yellowing_of_eyes, swelled_lymph_nodes, malaise, phlegm, chest_pain, blood_in_sputum \n",
            " actual_disease : Tuberculosis\n",
            "predicted_disease_sentence : The symptoms described could be indicative of a respiratory infection or disease, such as pneumonia or tuberculosis. It is important to consult a healthcare professional for proper diagnosis and treatment.\n",
            "\n",
            "\n",
            "1\n",
            "\n",
            "symptoms :  muscle_weakness, stiff_neck, swelling_joints, movement_stiffness, painful_walking \n",
            " actual_disease : Arthritis\n",
            "predicted_disease_sentence : Based on the information provided, the differential diagnosis for the symptoms of muscle weakness, stiff neck, swelling joints, movement stiffness, and painful walking could include conditions such as arthritis, syringomyelia, and inflammatory myopathies.\n",
            "\n",
            "\n",
            "1\n",
            "\n",
            "symptoms :  muscle_weakness, stiff_neck, swelling_joints, movement_stiffness, painful_walking \n",
            " actual_disease : Arthritis\n",
            "predicted_disease_sentence : The helpful answer is not available based on the provided information.\n",
            "\n",
            "\n",
            "0\n",
            "Accuracy: 0.7\n"
          ]
        }
      ],
      "source": [
        "correct_predictions = 0\n",
        "total_predictions = len(df)\n",
        "# Iterate through each row in the test dataset\n",
        "for index, row in df.iterrows():\n",
        "    symptoms = row['Symptoms']\n",
        "    actual_disease = row['Disease']\n",
        "    predicted_disease_sentence = search(symptoms)\n",
        "    print(f\"\\nsymptoms : {symptoms} \\n actual_disease : {actual_disease}\\npredicted_disease_sentence : {predicted_disease_sentence}\\n\\n\")\n",
        "    correct_predictions += compare(actual_disease,predicted_disease_sentence)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
